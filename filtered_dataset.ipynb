{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### data filtering",
   "id": "af188f643b976e74"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### imports",
   "id": "3ba0df8a06be8cf5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T10:21:50.838457Z",
     "start_time": "2025-05-10T10:21:50.834255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import pandasql as ps"
   ],
   "id": "be55cf326bbe14c",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### functions",
   "id": "c62bfdd43a12b80d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-10T10:21:50.859219Z",
     "start_time": "2025-05-10T10:21:50.848507Z"
    }
   },
   "source": [
    "def get_next_filename(base_filename, folder):\n",
    "    \"\"\"\n",
    "    Генерує унікальну назву файлу, додаючи +1 до номера.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    files = os.listdir(folder)\n",
    "\n",
    "    matching_files = [f for f in files if f.startswith(base_filename) and f.endswith(\".csv\")]\n",
    "\n",
    "    max_number = 0\n",
    "    for file in matching_files:\n",
    "        try:\n",
    "            number = int(file.replace(base_filename, \"\").replace(\".csv\", \"\").strip(\"_\"))\n",
    "            if number > max_number:\n",
    "                max_number = number\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    next_number = max_number + 1\n",
    "    return os.path.join(folder, f\"{base_filename}_{next_number}.csv\")\n",
    "def process_dataset(df):\n",
    "    \"\"\"\n",
    "    Processes the dataset according to the specified requirements:\n",
    "    1. Filters rows where position contains 'Data Scientist' or 'Data Science'.\n",
    "    2. Sorts rows by the 'period' field.\n",
    "    3. Adds a new column 'final_seniority' with the first non-empty value from seniority -> local experience seniority -> general experience seniority.\n",
    "    4. Adds a new column 'final_salary' as a concatenation of salary, bonuses flag, and bonuses amount.\n",
    "    5. Repeats rows based on the 'frequency' column value (converted to int). Defaults to 1 if frequency is missing or NaN.\n",
    "    6. Keeps only the columns: 'period', 'final_seniority', 'final_salary'.\n",
    "\n",
    "    :param df: Input DataFrame.\n",
    "    :return: Processed DataFrame.\n",
    "    \"\"\"\n",
    "    # Step 1: Filter rows where position contains 'Data Scientist' or 'Data Science'\n",
    "    filtered_df = df[df['position'].str.contains('Data Scientist|Data Science', na=False)]\n",
    "\n",
    "    # Step 2: Sort rows by the 'period' field\n",
    "    sorted_df = filtered_df.sort_values(by='period')\n",
    "\n",
    "    # Списки категорій\n",
    "    junior_values = [\n",
    "        '1', '1.5', '2', '0.25', 'менше 3 місяців', '0.5', '1 рік', '2 роки', 'півроку', '3 місяці', \n",
    "        'менше 3 місяців', '2.0', '1.0', '0.0', 'менше як 3 місяці', 'пів року', '1,5 року', '1-3 роки', \n",
    "        'до року', 'junior', 'немає тайтлу', 'intern/trainee', \"меньше 3 месяцев\"\n",
    "    ]\n",
    "    middle_values = [\n",
    "        '3', '4', '5', '4 роки', '3 роки', '5 років', '5.0', '4.0', '3.0', '4-6 років', 'middle'\n",
    "    ]\n",
    "    senior_values = [\n",
    "        '10 и более лет', '8', '9', '6', '7', '10 і більше років', '7 років', '6 років', '8 років', 'senior', '7.0', '8.0', '9.0', '10.0', '9 років',\n",
    "        '7-10 років', '10+ років', 'Tech Lead', 'Senior', 'Team Lead', 'Manager', 'Architect','Lead/Team Lead', 'Principal', '6.0', 'head'\n",
    "    ]\n",
    "    \n",
    "    # Функція для визначення категорії\n",
    "    def map_seniority(value):\n",
    "        if pd.isna(value):  # Якщо значення NaN, повертаємо None\n",
    "            return None\n",
    "        value = str(value).strip().lower()  # Приводимо значення до нижнього регістру для порівняння\n",
    "        if value in [v.lower() for v in junior_values]:\n",
    "            return 'junior'\n",
    "        elif value in [v.lower() for v in middle_values]:\n",
    "            return 'middle'\n",
    "        elif value in [v.lower() for v in senior_values]:\n",
    "            return 'senior'\n",
    "        return value  # Якщо значення не знайдено в жодній категорії\n",
    "    \n",
    "    # Step 1: Додати колонку 'final_seniority'\n",
    "    sorted_df['final_seniority'] = sorted_df.apply(\n",
    "        lambda row: next(\n",
    "            (val for val in [row['seniority'], row['general experience seniority'], row['local experience seniority']] if pd.notna(val)),\n",
    "            None\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Step 2: Оновити значення в колонці 'final_seniority' залежно від категорій\n",
    "    sorted_df['final_seniority'] = sorted_df['final_seniority'].apply(map_seniority)\n",
    "    # \n",
    "    # Step 4: Add 'final_salary' column\n",
    "    sorted_df['final_salary'] = sorted_df.apply(\n",
    "        lambda row: f\"{row['salary']} {row['bonuses flag']} {row['bonuses amount']}\",\n",
    "        axis=1\n",
    "    )\n",
    "    processed_df = apply_frequency(sorted_df)\n",
    "    final_columns = ['period', 'position', \"final_seniority\", \"final_salary\"]\n",
    "    combined_df = processed_df[final_columns]\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "def apply_frequency(df):\n",
    "    # Заповнюємо пропущені значення у 'frequency' значенням 1.0\n",
    "    df['frequency'] = df['frequency'].fillna(1.0)\n",
    "\n",
    "    # Замінюємо від'ємні значення на 0\n",
    "    df['frequency'] = df['frequency'].apply(lambda x: max(x, 0))\n",
    "\n",
    "    # Перетворюємо значення у 'frequency' на цілі числа\n",
    "    df['frequency'] = df['frequency'].astype(int)\n",
    "\n",
    "    # Повторюємо рядки на основі значення у frequency\n",
    "    df = df.loc[df.index.repeat(df['frequency'])].reset_index(drop=True)\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### variables",
   "id": "12e5938ef30661ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T10:21:50.876428Z",
     "start_time": "2025-05-10T10:21:50.873159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_path = \"raw_salary_compile/combined_salary_2.csv\"\n",
    "output_folder = \"filtered_dataset\" "
   ],
   "id": "ecddd66369556c21",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### main functions",
   "id": "cf9c067233359ba6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T10:21:51.376095Z",
     "start_time": "2025-05-10T10:21:50.881625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Usage Example\n",
    "# Assuming `df` is your input DataFrame\n",
    "\n",
    "output_path = get_next_filename(\"filtered_dataset\", output_folder)\n",
    "df = pd.read_csv(input_path, low_memory=False)  # Load your dataset\n",
    "\n",
    "processed_df = process_dataset(df)  # Process the dataset\n",
    "processed_df.to_csv(output_path, index=False)"
   ],
   "id": "1f62c0dd26c10dd",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T10:21:51.426808Z",
     "start_time": "2025-05-10T10:21:51.377605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv(\"filtered_dataset/filtered_dataset_3.csv\", low_memory=False)\n",
    "query = \"\"\"\n",
    "    SELECT DISTINCT `final_seniority`\n",
    "    FROM data\n",
    "\"\"\"\n",
    "\n",
    "# Виконання запиту\n",
    "unique_bonuses_flag = ps.sqldf(query, locals())\n",
    "\n",
    "# Виведення результату\n",
    "print(unique_bonuses_flag)"
   ],
   "id": "5694f2cbec5719fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  final_seniority\n",
      "0          junior\n",
      "1          senior\n",
      "2          middle\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T10:21:51.455143Z",
     "start_time": "2025-05-10T10:21:51.427334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data1 = pd.read_csv(\"filtered_dataset/filtered_dataset_3.csv\", low_memory=False)\n",
    "query = \"\"\"\n",
    "    SELECT count(*), final_seniority FROM data \n",
    "    group by final_seniority\n",
    "\"\"\"\n",
    "\n",
    "# Виконання запиту\n",
    "unique_bonuses_flag = ps.sqldf(query, locals())\n",
    "\n",
    "# Виведення результату\n",
    "print(unique_bonuses_flag)"
   ],
   "id": "292ffb4e025e63db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   count(*) final_seniority\n",
      "0      1459          junior\n",
      "1       962          middle\n",
      "2       717          senior\n"
     ]
    }
   ],
   "execution_count": 44
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
