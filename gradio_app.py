import gradio as gr
import pandas as pd
import numpy as np
from xgboost import XGBRegressor
import pickle
import os

# –ì–ª–æ–±–∞–ª—å–Ω—ñ –∑–º—ñ–Ω–Ω—ñ –¥–ª—è –∑–±–µ—Ä—ñ–≥–∞–Ω–Ω—è –º–æ–¥–µ–ª–µ–π
models = {}
feature_columns = []
#csv_path = os.path.join('.', 'cleaned_df', 'cleaned_df.csv')
csv_path = './cleaned_df/cleaned_df.csv'
def load_df(df_path):
    print(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞—Ç–∞—Å–µ—Ç—É")
    return pd.read_csv(df_path)


def prepare_features(df, lags=[2, 4]):
    """–ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–∑–Ω–∞–∫ –∑ –ª–∞–≥–∞–º–∏"""
    df = df.copy()
    for lag in lags:
        df[f'lag_{lag}'] = df['average_salary'].shift(lag)
    df.dropna(inplace=True)
    return df


def train_ml_model_for_seniority(df_cleaned, seniority, lags=[2]):
    df_sub = df_cleaned[df_cleaned['final_seniority'] == seniority].copy()
    df_sub = prepare_features(df_sub, lags=lags)

    target = 'average_salary'
    lag_features = [f'lag_{lag}' for lag in lags]
    features = ['gdp_mln_usd', 'exchange_rate_uah_usd', 'google_search_for_data_science', 
                     'final_consumption_expenditure', 'delta_gdp_mln_usd', 'percent_delta_gdp_mln_usd',
                     'consumer price index', 'average_salary_usd', 'delta_average_salary_usd',
                     'percent_delta_average_salary_usd', 'year',	'half', 'cleaned'] + lag_features

    train_df = df_sub.iloc[:-4]
    test_df = df_sub.iloc[-4:]

    X_train = train_df[features]
    y_train = train_df[target]

    model = XGBRegressor(random_state=42)
    model.fit(X_train, y_train)

    return model

def train_initial_models(df):
    """–¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –ø–æ—á–∞—Ç–∫–æ–≤–∏—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—ó"""
    
    print(f"‚úÖ –ü–æ—á–∞—Ç–æ–∫ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è")
    print(f"{df.head()}")

    for level in df['final_seniority'].unique():
        models[level] = train_ml_model_for_seniority(df, level)
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –¥–ª—è {level} –Ω–∞—Ç—Ä–µ–Ω–æ–≤–∞–Ω–∞")
    
    #return f"–ù–∞—Ç—Ä–µ–Ω–æ–≤–∞–Ω–æ {len(models)} –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ä—ñ–≤–Ω—ñ–≤: {', '.join(models.keys())}"

def predict_salary(seniority, gdp_mln_usd, exchange_rate, google_search, consumption_expenditure,
                  delta_gdp, percent_delta_gdp, cpi, avg_salary_usd, delta_salary_usd,
                  percent_delta_salary_usd, year, half, cleaned, lag_2, lag_4):
    """–ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –∑–∞—Ä–ø–ª–∞—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –≤—Ö—ñ–¥–Ω–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤"""
    
    global models, feature_columns
    
    if not models:
        return "‚ùå –ú–æ–¥–µ–ª—ñ –Ω–µ –Ω–∞—Ç—Ä–µ–Ω–æ–≤–∞–Ω—ñ. –°–ø–æ—á–∞—Ç–∫—É —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É–π—Ç–µ –¥–æ–¥–∞—Ç–æ–∫."
    
    if seniority not in models:
        available = ', '.join(models.keys())
        return f"‚ùå –ú–æ–¥–µ–ª—å –¥–ª—è '{seniority}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞. –î–æ—Å—Ç—É–ø–Ω—ñ: {available}"
    
    try:
        # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è DataFrame –∑ –≤—Ö—ñ–¥–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏ —É –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º—É –ø–æ—Ä—è–¥–∫—É
        # –ü–æ—Ä—è–¥–æ–∫ –º–∞—î –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—Ç–∏ —Ç–æ–º—É, —â–æ –æ—á—ñ–∫—É—î –º–æ–¥–µ–ª—å
        input_data = {
            'gdp_mln_usd': [gdp_mln_usd],
            'delta_gdp_mln_usd': [delta_gdp],
            'lag_2': [lag_2],
            'year': [year],
            'half': [half],
            'final_consumption_expenditure': [consumption_expenditure],
            'cleaned': [cleaned],
            'delta_average_salary_usd': [delta_salary_usd],
            'percent_delta_average_salary_usd': [percent_delta_salary_usd],
            'consumer price index': [cpi],
            'percent_delta_gdp_mln_usd': [percent_delta_gdp],
            'average_salary_usd': [avg_salary_usd],
            'exchange_rate_uah_usd': [exchange_rate],
            'google_search_for_data_science': [google_search]
        }
        
        df_input = pd.DataFrame(input_data)
        
        # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –ø–æ—Ä—è–¥–∫—É –æ–∑–Ω–∞–∫ –∑ –Ω–∞—Ç—Ä–µ–Ω–æ–≤–∞–Ω–æ—ó –º–æ–¥–µ–ª—ñ
        model = models[seniority]
        
        # –Ø–∫—â–æ —É –º–æ–¥–µ–ª—ñ —î –∞—Ç—Ä–∏–±—É—Ç feature_names_in_ (sklearn >= 0.24)
        if hasattr(model, 'feature_names_in_'):
            expected_features = model.feature_names_in_
        else:
            # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ø–æ—Ä—è–¥–æ–∫ –∑ –ø–æ–º–∏–ª–∫–∏
            expected_features = [
                'gdp_mln_usd', 'delta_gdp_mln_usd', 'lag_2', 'year', 'half', 
                'final_consumption_expenditure', 'cleaned', 'delta_average_salary_usd', 
                'percent_delta_average_salary_usd', 'consumer price index', 
                'percent_delta_gdp_mln_usd', 'average_salary_usd', 'exchange_rate_uah_usd', 
                'google_search_for_data_science'
            ]
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ –≤—Å—ñ—Ö –ø–æ—Ç—Ä—ñ–±–Ω–∏—Ö –æ–∑–Ω–∞–∫
        missing_features = [col for col in expected_features if col not in df_input.columns]
        if missing_features:
            return f"‚ùå –í—ñ–¥—Å—É—Ç–Ω—ñ –æ–∑–Ω–∞–∫–∏: {', '.join(missing_features)}"
        
        # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö —É –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º—É –ø–æ—Ä—è–¥–∫—É
        X_input = df_input[expected_features]
        
        # –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
        prediction = model.predict(X_input)[0]
        
        # –î–æ–¥–∞—Ç–∫–æ–≤—ñ —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫–∏
        salary_usd = prediction / exchange_rate
        
        result = f"""
üéØ **–ü—Ä–æ–≥–Ω–æ–∑ –∑–∞—Ä–ø–ª–∞—Ç–∏ –¥–ª—è {seniority.upper()}:**

üí∞ **–ü—Ä–æ–≥–Ω–æ–∑–æ–≤–∞–Ω–∞ –∑–∞—Ä–ø–ª–∞—Ç–∞:** {prediction:,.0f} USD
üìä **–ö—É—Ä—Å –¥–æ–ª–∞—Ä–∞:** {exchange_rate:.2f} UAH/USD

üìà **–í—Ö—ñ–¥–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏:**
‚Ä¢ GDP: {gdp_mln_usd:,} –º–ª–Ω USD
‚Ä¢ –ü–æ—à—É–∫–∏ "data science": {google_search}
‚Ä¢ –°–ø–æ–∂–∏–≤—á—ñ –≤–∏—Ç—Ä–∞—Ç–∏: {consumption_expenditure:,} –º–ª–Ω UAH
‚Ä¢ –Ü–Ω–¥–µ–∫—Å —Å–ø–æ–∂–∏–≤—á–∏—Ö —Ü—ñ–Ω: {cpi:.1f}
‚Ä¢ –†—ñ–∫/–ø—ñ–≤—Ä—ñ—á—á—è: {year}/{half}
‚Ä¢ –õ–∞–≥ 2 –ø–µ—Ä—ñ–æ–¥–∏: {lag_2:,.0f} UAH
"""
        
        return result
        
    except Exception as e:
        return f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—ñ: {str(e)}"


def load_custom_model(csv_file):
    """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≤–ª–∞—Å–Ω–æ—ó –º–æ–¥–µ–ª—ñ –∑ CSV —Ñ–∞–π–ª—É"""
    if csv_file is None:
        return "‚ùå –§–∞–π–ª –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ"
    
    try:
        result = train_initial_models(csv_file.name)
        return f"‚úÖ {result}"
    except Exception as e:
        return f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {str(e)}"


# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è Gradio —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É
def create_gradio_app():
    """–°—Ç–≤–æ—Ä–µ–Ω–Ω—è Gradio –¥–æ–¥–∞—Ç–∫—É –¥–ª—è –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –∑–∞—Ä–ø–ª–∞—Ç"""

    with gr.Blocks(title="üí∞ Salary Predictor", theme=gr.themes.Soft()) as app:
        gr.Markdown("""
        # üí∞ –ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è –∑–∞—Ä–ø–ª–∞—Ç –≤ IT
        
        –í–≤–µ–¥—ñ—Ç—å –µ–∫–æ–Ω–æ–º—ñ—á–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ —Ç–∞ –æ—Ç—Ä–∏–º–∞–π—Ç–µ –ø—Ä–æ–≥–Ω–æ–∑ –∑–∞—Ä–ø–ª–∞—Ç–∏ Data science —Å–ø–µ—Ü—ñ–∞–ª—ñ—Å—Ç—ñ–≤ –¥–ª—è —Ä—ñ–∑–Ω–∏—Ö —Ä—ñ–≤–Ω—ñ–≤ seniority
        """)
        
        gr.Markdown("---")
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### üìä –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑—É")
                
                seniority = gr.Dropdown(
                    choices=["junior", "middle", "senior"],
                    label="–†—ñ–≤–µ–Ω—å Seniority",
                    value="middle"
                )
                
                with gr.Row():
                    year = gr.Number(label="–†—ñ–∫", value=2024, precision=0)
                    half = gr.Dropdown(choices=[1, 2], label="–ü—ñ–≤—Ä—ñ—á—á—è", value=1)
                
                gdp = gr.Number(label="GDP (–º–ª–Ω USD)", value=153781)
                exchange_rate = gr.Number(label="–ö—É—Ä—Å UAH/USD", value=41.5)
                google_search = gr.Number(label="Google –ø–æ—à—É–∫–∏ 'data science'", value=75, precision=0)
                consumption = gr.Number(label="–°–ø–æ–∂–∏–≤—á—ñ –≤–∏—Ç—Ä–∞—Ç–∏ (–º–ª–Ω UAH)", value=150000)
                lag_2 = gr.Number(label="–õ–∞–≥ 2 (USD)", value=1160)
                with gr.Row():
                    delta_gdp = gr.Number(label="Œî GDP", value=0)
                    percent_delta_gdp = gr.Number(label="% Œî GDP", value=2.5)
                
                cpi = gr.Number(label="–Ü–Ω–¥–µ–∫—Å —Å–ø–æ–∂–∏–≤—á–∏—Ö —Ü—ñ–Ω", value=110)
                
                with gr.Row():
                    avg_salary_usd = gr.Number(label="–°–µ—Ä. –∑–∞—Ä–ø–ª–∞—Ç–∞ (USD)", value=1200)
                    delta_salary_usd = gr.Number(label="Œî –ó–∞—Ä–ø–ª–∞—Ç–∞ (USD)", value=50)
                
                percent_delta_salary = gr.Number(label="% Œî –ó–∞—Ä–ø–ª–∞—Ç–∞ (USD)", value=4)
                cleaned = gr.Dropdown(choices=[0, 1], label="–û—á–∏—â–µ–Ω—ñ –¥–∞–Ω—ñ", value=1)
                
                predict_btn = gr.Button("üéØ –ü–µ—Ä–µ–¥–±–∞—á–∏—Ç–∏ –∑–∞—Ä–ø–ª–∞—Ç—É", variant="primary", size="lg")
            
        with gr.Column(scale=1):
            gr.Markdown("### üìà –†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≥–Ω–æ–∑—É")
            prediction_output = gr.Markdown(value="–í–≤–µ–¥—ñ—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ —Ç–∞ –Ω–∞—Ç–∏—Å–Ω—ñ—Ç—å '–ü–µ—Ä–µ–¥–±–∞—á–∏—Ç–∏ –∑–∞—Ä–ø–ª–∞—Ç—É'")

        # –û–±—Ä–æ–±–Ω–∏–∫–∏ –ø–æ–¥—ñ–π
        predict_btn.click(
            fn=predict_salary,
            inputs=[seniority, gdp, exchange_rate, google_search, consumption,
                   delta_gdp, percent_delta_gdp, cpi, avg_salary_usd, delta_salary_usd,
                   percent_delta_salary, year, half, cleaned, lag_2, lag_4],
            outputs=prediction_output
        )
        
        gr.Markdown("""
        ---
        ### üìã –Ü–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó:
        1. **–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É–π—Ç–µ** –º–æ–¥–µ–ª—å –¥–µ–º–æ-–¥–∞–Ω–∏–º–∏ –∞–±–æ –∑–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ –≤–ª–∞—Å–Ω–∏–π CSV
        2. **–í–≤–µ–¥—ñ—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–∏** –µ–∫–æ–Ω–æ–º—ñ—á–Ω–æ–≥–æ —Å—Ç–∞–Ω—É —Ç–∞ –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ –∑–∞—Ä–ø–ª–∞—Ç–∏
        3. **–í–∏–±–µ—Ä—ñ—Ç—å seniority** —Ä—ñ–≤–µ–Ω—å (junior/middle/senior)
        4. **–ù–∞—Ç–∏—Å–Ω—ñ—Ç—å –ø–µ—Ä–µ–¥–±–∞—á–∏—Ç–∏** –¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –ø—Ä–æ–≥–Ω–æ–∑—É
        
        –ú–æ–¥–µ–ª—å –≤—Ä–∞—Ö–æ–≤—É—î –º–∞–∫—Ä–æ–µ–∫–æ–Ω–æ–º—ñ—á–Ω—ñ –ø–æ–∫–∞–∑–Ω–∏–∫–∏ —Ç–∞ —ñ—Å—Ç–æ—Ä–∏—á–Ω—ñ –¥–∞–Ω—ñ –∑–∞—Ä–ø–ª–∞—Ç.
        """)
    
    return app

# –ó–∞–ø—É—Å–∫ –¥–æ–¥–∞—Ç–∫—É
if __name__ == "__main__":
    df = load_df(csv_path)
    print(df.head())
    train_initial_models(df) 
    app = create_gradio_app()
    app.launch(
        share=True,
        server_name="0.0.0.0", 
        server_port=7860,
        show_error=True
    )