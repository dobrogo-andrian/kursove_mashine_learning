import gradio as gr
import pandas as pd
import numpy as np
from xgboost import XGBRegressor
import pickle
import os

# –ì–ª–æ–±–∞–ª—å–Ω—ñ –∑–º—ñ–Ω–Ω—ñ –¥–ª—è –∑–±–µ—Ä—ñ–≥–∞–Ω–Ω—è –º–æ–¥–µ–ª–µ–π
models = {}
feature_columns = []

def prepare_features(df, lags=[2, 4]):
    """–ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–∑–Ω–∞–∫ –∑ –ª–∞–≥–∞–º–∏"""
    df = df.copy()
    for lag in lags:
        df[f'lag_{lag}'] = df['average_salary'].shift(lag)
    df.dropna(inplace=True)
    return df

def train_initial_models(df_path=None):
    """–¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –ø–æ—á–∞—Ç–∫–æ–≤–∏—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—ó"""
    # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ–π–Ω–∏—Ö –¥–∞–Ω–∏—Ö —è–∫—â–æ CSV –Ω–µ –Ω–∞–¥–∞–Ω–æ
    if df_path is None:
        # –ì–µ–Ω–µ—Ä—É—î–º–æ —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω—ñ –¥–∞–Ω—ñ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—ó
        np.random.seed(42)
        n_samples = 50
        
        data = {
            'final_seniority': np.random.choice(['junior', 'middle', 'senior'], n_samples),
            'gdp_mln_usd': np.random.normal(180000, 20000, n_samples),
            'exchange_rate_uah_usd': np.random.normal(27.5, 2.5, n_samples),
            'google_search_for_data_science': np.random.randint(60, 100, n_samples),
            'final_consumption_expenditure': np.random.normal(150000, 15000, n_samples),
            'delta_gdp_mln_usd': np.random.normal(0, 5000, n_samples),
            'percent_delta_gdp_mln_usd': np.random.normal(2.5, 1.5, n_samples),
            'consumer price index': np.random.normal(110, 10, n_samples),
            'average_salary_usd': np.random.normal(1200, 400, n_samples),
            'delta_average_salary_usd': np.random.normal(50, 100, n_samples),
            'percent_delta_average_salary_usd': np.random.normal(4, 2, n_samples),
            'year': np.random.choice([2022, 2023, 2024], n_samples),
            'half': np.random.choice([1, 2], n_samples),
            'cleaned': np.random.choice([0, 1], n_samples),
            'average_salary': np.random.normal(35000, 10000, n_samples)
        }
        
        # –ö–æ—Ä–∏–≥—É—î–º–æ –∑–∞—Ä–ø–ª–∞—Ç–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ –¥–æ seniority
        for i in range(n_samples):
            if data['final_seniority'][i] == 'junior':
                data['average_salary'][i] = np.random.normal(25000, 5000)
                data['average_salary_usd'][i] = data['average_salary'][i] / data['exchange_rate_uah_usd'][i]
            elif data['final_seniority'][i] == 'middle':
                data['average_salary'][i] = np.random.normal(40000, 8000)
                data['average_salary_usd'][i] = data['average_salary'][i] / data['exchange_rate_uah_usd'][i]
            else:  # senior
                data['average_salary'][i] = np.random.normal(60000, 12000)
                data['average_salary_usd'][i] = data['average_salary'][i] / data['exchange_rate_uah_usd'][i]
        
        df = pd.DataFrame(data)
    else:
        df = pd.read_csv(df_path)
    
    global models, feature_columns
    
    # –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª–µ–π –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ seniority
    seniority_levels = df['final_seniority'].unique()
    
    for seniority in seniority_levels:
        print(f"–¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ –¥–ª—è {seniority}...")
        
        df_sub = df[df['final_seniority'] == seniority].copy()
        df_sub = prepare_features(df_sub, lags=[2, 4])
        
        if len(df_sub) < 10:
            continue
            
        target = 'average_salary'
        lag_features = ['lag_2', 'lag_4']
        
        base_features = ['gdp_mln_usd', 'exchange_rate_uah_usd', 'google_search_for_data_science', 
                         'final_consumption_expenditure', 'delta_gdp_mln_usd', 'percent_delta_gdp_mln_usd',
                         'consumer price index', 'average_salary_usd', 'delta_average_salary_usd',
                         'percent_delta_average_salary_usd', 'year', 'half', 'cleaned']
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ –∫–æ–ª–æ–Ω–æ–∫
        available_features = [f for f in base_features if f in df_sub.columns]
        features = available_features + lag_features
        
        if not feature_columns:  # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Å–ø–∏—Å–æ–∫ –æ–∑–Ω–∞–∫
            feature_columns = features
        
        X = df_sub[features]
        y = df_sub[target]
        
        # –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ
        model = XGBRegressor(random_state=42, n_estimators=100)
        model.fit(X, y)
        
        models[seniority] = model
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –¥–ª—è {seniority} –Ω–∞—Ç—Ä–µ–Ω–æ–≤–∞–Ω–∞")
    
    return f"–ù–∞—Ç—Ä–µ–Ω–æ–≤–∞–Ω–æ {len(models)} –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ä—ñ–≤–Ω—ñ–≤: {', '.join(models.keys())}"

def predict_salary(seniority, gdp_mln_usd, exchange_rate, google_search, consumption_expenditure,
                  delta_gdp, percent_delta_gdp, cpi, avg_salary_usd, delta_salary_usd,
                  percent_delta_salary_usd, year, half, cleaned, lag_2, lag_4):
    """–ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –∑–∞—Ä–ø–ª–∞—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –≤—Ö—ñ–¥–Ω–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤"""
    
    global models, feature_columns
    
    if not models:
        return "‚ùå –ú–æ–¥–µ–ª—ñ –Ω–µ –Ω–∞—Ç—Ä–µ–Ω–æ–≤–∞–Ω—ñ. –°–ø–æ—á–∞—Ç–∫—É —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É–π—Ç–µ –¥–æ–¥–∞—Ç–æ–∫."
    
    if seniority not in models:
        available = ', '.join(models.keys())
        return f"‚ùå –ú–æ–¥–µ–ª—å –¥–ª—è '{seniority}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞. –î–æ—Å—Ç—É–ø–Ω—ñ: {available}"
    
    try:
        # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è DataFrame –∑ –≤—Ö—ñ–¥–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏
        input_data = {
            'gdp_mln_usd': [gdp_mln_usd],
            'exchange_rate_uah_usd': [exchange_rate],
            'google_search_for_data_science': [google_search],
            'final_consumption_expenditure': [consumption_expenditure],
            'delta_gdp_mln_usd': [delta_gdp],
            'percent_delta_gdp_mln_usd': [percent_delta_gdp],
            'consumer price index': [cpi],
            'average_salary_usd': [avg_salary_usd],
            'delta_average_salary_usd': [delta_salary_usd],
            'percent_delta_average_salary_usd': [percent_delta_salary_usd],
            'year': [year],
            'half': [half],
            'cleaned': [cleaned],
            'lag_2': [lag_2],
            'lag_4': [lag_4]
        }
        
        df_input = pd.DataFrame(input_data)
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ –≤—Å—ñ—Ö –ø–æ—Ç—Ä—ñ–±–Ω–∏—Ö –æ–∑–Ω–∞–∫
        missing_features = [col for col in feature_columns if col not in df_input.columns]
        if missing_features:
            return f"‚ùå –í—ñ–¥—Å—É—Ç–Ω—ñ –æ–∑–Ω–∞–∫–∏: {', '.join(missing_features)}"
        
        # –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
        model = models[seniority]
        X_input = df_input[feature_columns]
        prediction = model.predict(X_input)[0]
        
        # –î–æ–¥–∞—Ç–∫–æ–≤—ñ —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫–∏
        salary_usd = prediction / exchange_rate
        
        result = f"""
üéØ **–ü—Ä–æ–≥–Ω–æ–∑ –∑–∞—Ä–ø–ª–∞—Ç–∏ –¥–ª—è {seniority.upper()}:**

üí∞ **–ü—Ä–æ–≥–Ω–æ–∑–æ–≤–∞–Ω–∞ –∑–∞—Ä–ø–ª–∞—Ç–∞:** {prediction:,.0f} UAH
üíµ **–í –¥–æ–ª–∞—Ä–∞—Ö –°–®–ê:** ${salary_usd:,.0f} USD
üìä **–ö—É—Ä—Å –¥–æ–ª–∞—Ä–∞:** {exchange_rate:.2f} UAH/USD

üìà **–í—Ö—ñ–¥–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏:**
‚Ä¢ GDP: {gdp_mln_usd:,} –º–ª–Ω USD
‚Ä¢ –ü–æ—à—É–∫–∏ "data science": {google_search}
‚Ä¢ –°–ø–æ–∂–∏–≤—á—ñ –≤–∏—Ç—Ä–∞—Ç–∏: {consumption_expenditure:,} –º–ª–Ω UAH
‚Ä¢ –Ü–Ω–¥–µ–∫—Å —Å–ø–æ–∂–∏–≤—á–∏—Ö —Ü—ñ–Ω: {cpi:.1f}
‚Ä¢ –†—ñ–∫/–ø—ñ–≤—Ä—ñ—á—á—è: {year}/{half}
‚Ä¢ –õ–∞–≥ 2 –ø–µ—Ä—ñ–æ–¥–∏: {lag_2:,.0f} UAH
‚Ä¢ –õ–∞–≥ 4 –ø–µ—Ä—ñ–æ–¥–∏: {lag_4:,.0f} UAH
"""
        
        return result
        
    except Exception as e:
        return f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—ñ: {str(e)}"

def load_custom_model(csv_file):
    """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≤–ª–∞—Å–Ω–æ—ó –º–æ–¥–µ–ª—ñ –∑ CSV —Ñ–∞–π–ª—É"""
    if csv_file is None:
        return "‚ùå –§–∞–π–ª –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ"
    
    try:
        result = train_initial_models(csv_file.name)
        return f"‚úÖ {result}"
    except Exception as e:
        return f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {str(e)}"

# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è Gradio —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É
def create_gradio_app():
    """–°—Ç–≤–æ—Ä–µ–Ω–Ω—è Gradio –¥–æ–¥–∞—Ç–∫—É –¥–ª—è –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –∑–∞—Ä–ø–ª–∞—Ç"""
    
    with gr.Blocks(title="üí∞ Salary Predictor", theme=gr.themes.Soft()) as app:
        gr.Markdown("""
        # üí∞ –ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è –∑–∞—Ä–ø–ª–∞—Ç –≤ IT
        
        –í–≤–µ–¥—ñ—Ç—å –µ–∫–æ–Ω–æ–º—ñ—á–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ —Ç–∞ –æ—Ç—Ä–∏–º–∞–π—Ç–µ –ø—Ä–æ–≥–Ω–æ–∑ –∑–∞—Ä–ø–ª–∞—Ç–∏ –¥–ª—è —Ä—ñ–∑–Ω–∏—Ö —Ä—ñ–≤–Ω—ñ–≤ seniority
        """)
        
        with gr.Row():
            with gr.Column():
                gr.Markdown("### üîß –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –º–æ–¥–µ–ª—ñ")
                init_btn = gr.Button("üöÄ –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –∑ –¥–µ–º–æ-–¥–∞–Ω–∏–º–∏", variant="primary")
                
                gr.Markdown("### üìÅ –ê–±–æ –∑–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ –≤–ª–∞—Å–Ω—ñ –¥–∞–Ω—ñ")
                csv_upload = gr.File(label="CSV —Ñ–∞–π–ª", file_types=[".csv"])
                load_btn = gr.Button("üìä –¢—Ä–µ–Ω—É–≤–∞—Ç–∏ –Ω–∞ –≤–ª–∞—Å–Ω–∏—Ö –¥–∞–Ω–∏—Ö")
                
                init_status = gr.Textbox(label="–°—Ç–∞—Ç—É—Å", interactive=False)
        
        gr.Markdown("---")
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### üìä –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑—É")
                
                seniority = gr.Dropdown(
                    choices=["junior", "middle", "senior"],
                    label="–†—ñ–≤–µ–Ω—å Seniority",
                    value="middle"
                )
                
                with gr.Row():
                    year = gr.Number(label="–†—ñ–∫", value=2024, precision=0)
                    half = gr.Dropdown(choices=[1, 2], label="–ü—ñ–≤—Ä—ñ—á—á—è", value=1)
                
                gdp = gr.Number(label="GDP (–º–ª–Ω USD)", value=180000)
                exchange_rate = gr.Number(label="–ö—É—Ä—Å UAH/USD", value=27.5)
                google_search = gr.Number(label="Google –ø–æ—à—É–∫–∏ 'data science'", value=75, precision=0)
                consumption = gr.Number(label="–°–ø–æ–∂–∏–≤—á—ñ –≤–∏—Ç—Ä–∞—Ç–∏ (–º–ª–Ω UAH)", value=150000)
                
                with gr.Row():
                    delta_gdp = gr.Number(label="Œî GDP", value=0)
                    percent_delta_gdp = gr.Number(label="% Œî GDP", value=2.5)
                
                cpi = gr.Number(label="–Ü–Ω–¥–µ–∫—Å —Å–ø–æ–∂–∏–≤—á–∏—Ö —Ü—ñ–Ω", value=110)
                
                with gr.Row():
                    avg_salary_usd = gr.Number(label="–°–µ—Ä. –∑–∞—Ä–ø–ª–∞—Ç–∞ (USD)", value=1200)
                    delta_salary_usd = gr.Number(label="Œî –ó–∞—Ä–ø–ª–∞—Ç–∞ (USD)", value=50)
                
                percent_delta_salary = gr.Number(label="% Œî –ó–∞—Ä–ø–ª–∞—Ç–∞ (USD)", value=4)
                cleaned = gr.Dropdown(choices=[0, 1], label="–û—á–∏—â–µ–Ω—ñ –¥–∞–Ω—ñ", value=1)
                
                gr.Markdown("### üîÑ –õ–∞–≥–∏ (–ø–æ–ø–µ—Ä–µ–¥–Ω—ñ –∑–∞—Ä–ø–ª–∞—Ç–∏)")
                lag_2 = gr.Number(label="–ó–∞—Ä–ø–ª–∞—Ç–∞ 2 –ø–µ—Ä—ñ–æ–¥–∏ –Ω–∞–∑–∞–¥ (UAH)", value=35000)
                lag_4 = gr.Number(label="–ó–∞—Ä–ø–ª–∞—Ç–∞ 4 –ø–µ—Ä—ñ–æ–¥–∏ –Ω–∞–∑–∞–¥ (UAH)", value=33000)
                
                predict_btn = gr.Button("üéØ –ü–µ—Ä–µ–¥–±–∞—á–∏—Ç–∏ –∑–∞—Ä–ø–ª–∞—Ç—É", variant="primary", size="lg")
            
            with gr.Column(scale=1):
                gr.Markdown("### üìà –†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≥–Ω–æ–∑—É")
                prediction_output = gr.Markdown(value="–í–≤–µ–¥—ñ—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ —Ç–∞ –Ω–∞—Ç–∏—Å–Ω—ñ—Ç—å '–ü–µ—Ä–µ–¥–±–∞—á–∏—Ç–∏ –∑–∞—Ä–ø–ª–∞—Ç—É'")
        
        # –û–±—Ä–æ–±–Ω–∏–∫–∏ –ø–æ–¥—ñ–π
        init_btn.click(
            fn=lambda: train_initial_models(),
            outputs=init_status
        )
        
        load_btn.click(
            fn=load_custom_model,
            inputs=csv_upload,
            outputs=init_status
        )
        
        predict_btn.click(
            fn=predict_salary,
            inputs=[seniority, gdp, exchange_rate, google_search, consumption,
                   delta_gdp, percent_delta_gdp, cpi, avg_salary_usd, delta_salary_usd,
                   percent_delta_salary, year, half, cleaned, lag_2, lag_4],
            outputs=prediction_output
        )
        
        gr.Markdown("""
        ---
        ### üìã –Ü–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó:
        1. **–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É–π—Ç–µ** –º–æ–¥–µ–ª—å –¥–µ–º–æ-–¥–∞–Ω–∏–º–∏ –∞–±–æ –∑–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ –≤–ª–∞—Å–Ω–∏–π CSV
        2. **–í–≤–µ–¥—ñ—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–∏** –µ–∫–æ–Ω–æ–º—ñ—á–Ω–æ–≥–æ —Å—Ç–∞–Ω—É —Ç–∞ –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ –∑–∞—Ä–ø–ª–∞—Ç–∏
        3. **–í–∏–±–µ—Ä—ñ—Ç—å seniority** —Ä—ñ–≤–µ–Ω—å (junior/middle/senior)
        4. **–ù–∞—Ç–∏—Å–Ω—ñ—Ç—å –ø–µ—Ä–µ–¥–±–∞—á–∏—Ç–∏** –¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –ø—Ä–æ–≥–Ω–æ–∑—É
        
        –ú–æ–¥–µ–ª—å –≤—Ä–∞—Ö–æ–≤—É—î –º–∞–∫—Ä–æ–µ–∫–æ–Ω–æ–º—ñ—á–Ω—ñ –ø–æ–∫–∞–∑–Ω–∏–∫–∏ —Ç–∞ —ñ—Å—Ç–æ—Ä–∏—á–Ω—ñ –¥–∞–Ω—ñ –∑–∞—Ä–ø–ª–∞—Ç.
        """)
    
    return app

# –ó–∞–ø—É—Å–∫ –¥–æ–¥–∞—Ç–∫—É
if __name__ == "__main__":
    app = create_gradio_app()
    app.launch(
        share=True,
        server_name="0.0.0.0", 
        server_port=7860,
        show_error=True
    )